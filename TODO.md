# TODO

- [x] releases of applications should be creating tags in the git repo with the application name and version but flux isn't doing this. fix this
- [x] evaluate our use of namespaces in traefik and the duplication of resources between platform application directories. Is this achieving anything or just overcomplicating things? e.g. we have to duplicate our forward-auth middleware configuration and certificate.yaml across multiple platform apps now.
  - **Resolution**: Reorganized into two-tier namespace model (platform + applications) aligned with repo structure. Middleware duplication across 4 namespaces is acceptable trade-off vs complexity of cross-namespace references.
- [x] there are a lot of places where the old "monitoring" namespace is mentioned, and a lot of places where the "default" namespace is used or assumed. It is especially important to correct this in the bootstrap scripts and documentation. Comb through this and make sure the namespace is explicit where needed.
- [x] review the longhorn backup jobs. There seem to be some jobs that are backing up some things but they are referencing secrets that no longer exist. Explain exactly how these cron jobs are supposed to work, and what our backup process it and document it. Only the ciritical volumes should be being backed up, i.e. postgres and authelia primarily. We seem to have a lot of buckets, our backup strategy is all over the place. It looks like there's currently a massive backup of the registry somewhere as well: we should NOT be backup up the registry.
  - **Findings**: Documented in `BACKUP_STRATEGY.md`. Three secrets missing (`pg-backup-s3`, `etcd-backup-s3`, `s3-credentials`), causing all backup jobs to fail. Longhorn weekly backup exists but backs up zero volumes. Registry is NOT being backed up. Need to create secrets and configure Grafana volume backup.
- [x] grafana connections for loki and prometheus seem to be broken, so we need to fix that. Presumably the plugin that runs this has stopped running for some reason. Investigate and resolve.
- [x] following from the above: we need to set up etcd backups. Investigate the best way of doing this. There is a cronjob currently but it doesn't work. Remove the faulty cronjob and create a working solution, following the most standard route that is achievable with our current setup.
  - **Resolution**: k3s uses SQLite datastore, not etcd. Implemented k3s-sqlite-backup-s3 CronJob that backs up SQLite database and server token to S3 daily. Updated documentation to reflect actual architecture.
- [x] during the migration towards the dual namespace system, we had a lot of issues with secrets. Can we re-do the secrets audit and verify that all and only the required secrets are present in the cluster. You need to check and update the `SECRETS.md` documentation. This in in preparation for setting up SOPS so should be comprehensive.
- [x] set up SOPS for secrets management instead of current manual imperative approach
  - **Resolution**: Implemented SOPS with age encryption for all secrets. Created `.sops.yaml` configuration, migration script (`scripts/migrate-secret-to-sops.sh`), and Flux Kustomizations for namespace-specific secret deployment. All 12 secrets migrated to encrypted storage in git: flux-system (2), platform (6), applications (1), infrastructure (3). Secrets now version-controlled, encrypted at rest, and automatically deployed by Flux. Updated BOOTSTRAP.md and SECRETS.md with complete SOPS management procedures. Bootstrap requires `sops-age` secret creation and flux-system Kustomization patch for SOPS decryption (persists in etcd).
- [x] Check the connect-k8s script - when run in Claude Code it hangs forever, but run in a normal shell it exits as expected. It's essential that all of our scripts run well within Claude Code.
  - **Resolution**: SSH tunnel wasn't properly detached from shell. Fixed by redirecting stdin/stdout/stderr (`</dev/null >/dev/null 2>&1`) and using `disown` to remove background job from shell's job table. Script now exits cleanly while tunnel continues running.
- [x] is it possible for our longhorn volumes to be given more readable names? They should include the name of the service they are for.
  - **Resolution**: Volume names are GUIDs generated by Kubernetes (from PVC UID) and cannot be changed. However, PVCs have readable names. Use `kubectl get pvc -A` to see human-readable names, or view volumes in Longhorn UI which shows PVC names alongside GUIDs.
- [ ] Grafana dashboards.  Secondly, we have a bunch of dashboards that come bundled with the plugins, but it's not clear which ones are actually useful for our setup. We need to evaluate the approach. Should we be storing dashboards in the git repo or is it sufficient to store them in Grafana itself. Realistically, we only need one overview dashboard for the node/cluster including performance metrics, number of alerts, flagging any warnings from the logs, and one dashboard per application (currently just the ruby test application).
- [ ] rename platform/postgresql-new to simply platform/postgresql. Pay careful attention to the PVC: make sure that the same PVC is used for the new kustomization so that we have no issues with data loss
- [ ] add readmes to all of the subfolders of platform. These should contain a brief summary of what the folder contains, including e.g. a list of what services are deployed.
- [ ] does the file `platform/kustomization.yaml` actually get used for anything? It seems to be a duplication of the config in the `clusters/prod` folder. Investigate what it is used for and delete if it's unnecessary.
- [ ] what is `kube-prometheus-stack` and why does it appear all over the place. Is it an actual thing or something that's been invented here? Ideally our monitoring pods in platform would just have the actual names of the service. E.g. loki is named correctly, but grafana is named kube-prometheus-stack-grafana. Fix this so that pods are named consistently, and remove references to kube-prometheus-stack if it is your invention.
