---
apiVersion: v1
kind: ConfigMap
metadata:
  name: s3-metrics-script
  namespace: monitoring
data:
  collect-metrics.sh: |
    #!/bin/bash
    set -e

    # Get S3 endpoint from environment
    ENDPOINT="${AWS_ENDPOINTS}"
    PUSHGATEWAY_URL="${PUSHGATEWAY_URL:-http://kube-prometheus-stack-prometheus-pushgateway.monitoring.svc.cluster.local:9091}"

    echo "Collecting S3 storage metrics from ${ENDPOINT}"

    # List all buckets
    BUCKETS=$(aws s3 ls --endpoint-url="${ENDPOINT}" | awk '{print $3}')

    if [ -z "$BUCKETS" ]; then
      echo "No buckets found"
      exit 0
    fi

    TOTAL_SIZE=0
    TOTAL_OBJECTS=0

    # Collect metrics for each bucket
    for BUCKET in $BUCKETS; do
      echo "Processing bucket: ${BUCKET}"

      # Get bucket size and object count
      # Note: This uses recursive ls and sums up file sizes
      BUCKET_DATA=$(aws s3 ls s3://${BUCKET} --endpoint-url="${ENDPOINT}" --recursive --summarize | grep -E "Total (Size|Objects)")

      SIZE=$(echo "$BUCKET_DATA" | grep "Total Size" | awk '{print $3}')
      OBJECTS=$(echo "$BUCKET_DATA" | grep "Total Objects" | awk '{print $3}')

      # Default to 0 if empty
      SIZE=${SIZE:-0}
      OBJECTS=${OBJECTS:-0}

      TOTAL_SIZE=$((TOTAL_SIZE + SIZE))
      TOTAL_OBJECTS=$((TOTAL_OBJECTS + OBJECTS))

      echo "Bucket ${BUCKET}: ${SIZE} bytes, ${OBJECTS} objects"

      # Push per-bucket metrics
      cat <<EOF | curl --data-binary @- "${PUSHGATEWAY_URL}/metrics/job/s3_storage/instance/${BUCKET}"
    # TYPE s3_bucket_size_bytes gauge
    # HELP s3_bucket_size_bytes Total size of objects in S3 bucket in bytes
    s3_bucket_size_bytes{bucket="${BUCKET}"} ${SIZE}
    # TYPE s3_bucket_objects_total gauge
    # HELP s3_bucket_objects_total Total number of objects in S3 bucket
    s3_bucket_objects_total{bucket="${BUCKET}"} ${OBJECTS}
    EOF
    done

    # Convert total size to GB for easier reading
    TOTAL_SIZE_GB=$(echo "scale=2; ${TOTAL_SIZE} / 1073741824" | bc)

    echo "Total across all buckets: ${TOTAL_SIZE} bytes (${TOTAL_SIZE_GB} GB), ${TOTAL_OBJECTS} objects"

    # Push total metrics
    cat <<EOF | curl --data-binary @- "${PUSHGATEWAY_URL}/metrics/job/s3_storage/instance/total"
    # TYPE s3_total_size_bytes gauge
    # HELP s3_total_size_bytes Total size of all objects across all S3 buckets in bytes
    s3_total_size_bytes ${TOTAL_SIZE}
    # TYPE s3_total_objects gauge
    # HELP s3_total_objects Total number of objects across all S3 buckets
    s3_total_objects ${TOTAL_OBJECTS}
    EOF

    echo "Metrics pushed successfully"
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: s3-metrics-collector
  namespace: monitoring
spec:
  # Run every 15 minutes
  schedule: "*/15 * * * *"
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 2
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      backoffLimit: 2
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: collector
            image: amazon/aws-cli:latest
            command:
            - /bin/bash
            - /scripts/collect-metrics.sh
            env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: AWS_ENDPOINTS
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_ENDPOINTS
            - name: AWS_DEFAULT_REGION
              value: "nbg1"
            - name: PUSHGATEWAY_URL
              value: "http://kube-prometheus-stack-prometheus-pushgateway.monitoring.svc.cluster.local:9091"
            volumeMounts:
            - name: scripts
              mountPath: /scripts
            resources:
              requests:
                cpu: 10m
                memory: 32Mi
              limits:
                cpu: 100m
                memory: 128Mi
          volumes:
          - name: scripts
            configMap:
              name: s3-metrics-script
              defaultMode: 0755
# NOTE: s3-credentials secret must be created manually during bootstrap
# kubectl get secret longhorn-backup -n longhorn-system -o yaml | \
#   sed 's/namespace: longhorn-system/namespace: monitoring/' | \
#   sed 's/name: longhorn-backup/name: s3-credentials/' | \
#   grep -v 'uid:\|resourceVersion:\|creationTimestamp:' | kubectl apply -f -
